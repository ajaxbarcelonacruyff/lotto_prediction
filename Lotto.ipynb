{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPlO5M7fl8f3S+0pksjbT1F"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Script: https://miyashinblog.com/ailoto6-kairyouban/\n",
        "# Results: https://en.lottolyzer.com/history/new-zealand/nz-lotto/page/1/per-page/50/summary-view\n",
        "%cd"
      ],
      "metadata": {
        "id": "WzaOTWKHulcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XxAaa0tj61bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tflearn"
      ],
      "metadata": {
        "id": "FUEqHjBluRz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo-uyJZws3yS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tflearn\n",
        "import time\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PredictionLSTM:\n",
        "\n",
        "    def __init__(self):\n",
        "        # LSTM訓練パラメータ設定\n",
        "        self.steps_of_history = 10\n",
        "        self.steps_of_furture = 10\n",
        "        self.units = 5\n",
        "        self.epochs = 10\n",
        "        self.batch_size = 5\n",
        "\n",
        "    # データセット作成\n",
        "    def create_dataset(self, data):\n",
        "        x, y = [], []\n",
        "        for i in range(0, len(data) - self.steps_of_history, self.steps_of_furture):\n",
        "            a = i + self.steps_of_history\n",
        "            x.append(data[i:a])\n",
        "            y.append(data[a])\n",
        "        x = np.reshape(np.array(x), [-1, self.steps_of_history, 1])\n",
        "        y = np.reshape(np.array(y), [-1, 1])\n",
        "        return x, y\n",
        "\n",
        "    # 予測用データ作成\n",
        "    def create_predict_dataset(self, data):\n",
        "        latest_x = np.array([data[-self.steps_of_history:]])\n",
        "        latest_x = np.reshape(latest_x, (-1, self.steps_of_history, 1))\n",
        "        return latest_x\n",
        "\n",
        "    # 訓練、評価データ分割\n",
        "    def split_dataset(self, x, y, test_size=0.1):\n",
        "        pos = round(len(x) * (1 - test_size))\n",
        "        train_x, train_y = x[:pos], y[:pos]\n",
        "        test_x, test_y = x[pos:], y[pos:]\n",
        "        return train_x, train_y, test_x, test_y\n",
        "\n",
        "    # モデル作成\n",
        "    def _create_model_by_tflearn(self):\n",
        "        net = tflearn.input_data(shape=[None, self.steps_of_history, 1])\n",
        "\n",
        "        # LSTM\n",
        "        net = tflearn.lstm(net, n_units=self.units)\n",
        "\n",
        "        # GRU\n",
        "        # net = tflearn.gru(net, n_units=self.units)\n",
        "\n",
        "        # GRU 複数層\n",
        "        # net = tflearn.gru(net, n_units=self.units, return_seq=True)\n",
        "        # net = tflearn.gru(net, n_units=self.units)\n",
        "        net = tflearn.fully_connected(net, 1, activation='linear')\n",
        "        net = tflearn.regression(net, optimizer='Adam', learning_rate=0.01, loss='mean_square')\n",
        "\n",
        "        model = tflearn.DNN(net, tensorboard_verbose=0)\n",
        "\n",
        "        return model\n",
        "\n",
        "    # 訓練\n",
        "    def train(self, train_x, train_y):\n",
        "        model = self._create_model_by_tflearn()\n",
        "        model.fit(train_x, train_y, validation_set=0.1, batch_size=self.batch_size, n_epoch=self.epochs)\n",
        "\n",
        "        return model\n",
        "\n",
        "    # 予測\n",
        "    def predict(self, model, data):\n",
        "        return model.predict(data)\n",
        "\n",
        "    # 評価誤差アルゴリズム\n",
        "    # RMSE(Root Mean Squared Error)\n",
        "    def rmse(self, y_pred, y_true):\n",
        "        return np.sqrt(((y_true - y_pred) ** 2).mean())\n",
        "\n",
        "    # RMSLE(Root Mean Squared Logarithmic Error)\n",
        "    def rmsle(self, y_pred, y_true):\n",
        "        return np.sqrt(np.square(np.log(y_true + 1) - np.log(y_pred + 1)).mean())\n",
        "\n",
        "    # MAE(Mean Absolute Error)\n",
        "    def mae(self, y_pred, y_true):\n",
        "        return np.mean(np.abs((y_true - y_pred)))\n",
        "\n",
        "    # MAPE(Mean Absolute Percentage Error)\n",
        "    def mape(self, y_pred, y_true):\n",
        "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "\n",
        "\n",
        "def main_process():\n",
        "    START_TIME = time.time()\n",
        "\n",
        "    dataframe = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/lotto/lotto.csv')  # 学習させる過去の当選結果のパス(.csv)\n",
        "    number1 = dataframe['main1']\n",
        "    number2 = dataframe['main2'] - dataframe['main1']\n",
        "    number3 = dataframe['main3'] - dataframe['main2']\n",
        "    number4 = dataframe['main4'] - dataframe['main3']\n",
        "    number5 = dataframe['main5'] - dataframe['main4']\n",
        "    number6 = dataframe['main6'] - dataframe['main5']\n",
        "    bonus = dataframe['bonus']\n",
        "\n",
        "    #print(number2)\n",
        "\n",
        "    header_name_list = [number1, number2, number3, number4, number5, number6, bonus]\n",
        "\n",
        "    # 予測結果を最後にリストで表すための準備\n",
        "    prediction_results = {}\n",
        "    i = 1\n",
        "\n",
        "    for header in header_name_list:\n",
        "\n",
        "        # csvから読み込んだデータをint型に変換\n",
        "        data = header.astype(int)\n",
        "        data = data.values.reshape(data.shape[0], 1).astype(dtype=np.float32)\n",
        "\n",
        "        # 正規化\n",
        "        scaler = preprocessing.MinMaxScaler()\n",
        "        data = scaler.fit_transform(data)\n",
        "\n",
        "        # LSTMインスタンス作成\n",
        "        lstm = PredictionLSTM()\n",
        "\n",
        "        # 訓練、評価データ作成\n",
        "        x, y = lstm.create_dataset(data)\n",
        "        train_x, train_y, test_x, test_y = lstm.split_dataset(x, y)\n",
        "\n",
        "        model = lstm.train(train_x, train_y)\n",
        "\n",
        "        # 評価\n",
        "        train_predict = lstm.predict(model, train_x)\n",
        "        test_predict = lstm.predict(model, test_x)\n",
        "\n",
        "        # RMSE(Root Mean Squared Error)\n",
        "        train_score = lstm.rmse(train_y, train_predict)\n",
        "        test_score = lstm.rmse(test_y, test_predict)\n",
        "        print(\"Train Score: {0:.3f} RMSE\".format(train_score))\n",
        "        print(\"Test  Score: {0:.3f} RMSE\".format(test_score))\n",
        "\n",
        "        # 予測\n",
        "        latest_x = lstm.create_predict_dataset(data)\n",
        "        next_prediction = model.predict(latest_x)\n",
        "        next_prediction = scaler.inverse_transform(next_prediction)\n",
        "        print(str(header), '=', \"Next prediction: {0:.0f}\".format(list(next_prediction)[0][0]))\n",
        "\n",
        "        print(\"Time: {0:.1f}sec\".format(time.time() - START_TIME))\n",
        "\n",
        "        if (i == 1):\n",
        "\n",
        "            # 予測値を四捨五入して辞書に格納\n",
        "            prediction_results['number1'] = int(round(next_prediction[0][0]))\n",
        "\n",
        "        elif (i == 2):\n",
        "            prediction_results['number2'] = int(round(next_prediction[0][0])) + prediction_results['number1']\n",
        "\n",
        "        elif (i == 3):\n",
        "            prediction_results['number3'] = int(round(next_prediction[0][0])) + prediction_results['number2']\n",
        "\n",
        "        elif (i == 4):\n",
        "            prediction_results['number4'] = int(round(next_prediction[0][0])) + prediction_results['number3']\n",
        "\n",
        "        elif (i == 5):\n",
        "            prediction_results['number5'] = int(round(next_prediction[0][0])) + prediction_results['number4']\n",
        "\n",
        "        elif (i == 6):\n",
        "            prediction_results['number6'] = int(round(next_prediction[0][0])) + prediction_results['number5']\n",
        "\n",
        "        else:\n",
        "            prediction_results['bonus'] = int(round(next_prediction[0][0]))\n",
        "\n",
        "        # モデルをリセット\n",
        "        # 22/2/20 エラー改修 tf. → tf.compat.v1.\n",
        "        tf.compat.v1.reset_default_graph()\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    return prediction_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prediction_results = main_process()\n",
        "    while (prediction_results['number6'] >= 41 \\\n",
        "           or prediction_results['bonus'] >= 41\\\n",
        "        or prediction_results['bonus'] == prediction_results['number6'] \\\n",
        "        or prediction_results['bonus'] == prediction_results['number5'] \\\n",
        "        or prediction_results['bonus'] == prediction_results['number4'] \\\n",
        "        or prediction_results['bonus'] == prediction_results['number3'] \\\n",
        "        or prediction_results['bonus'] == prediction_results['number2'] \\\n",
        "        or prediction_results['bonus'] == prediction_results['number1'] \\\n",
        "        ):\n",
        "        prediction_results = main_process()\n",
        "\n",
        "print(prediction_results)"
      ],
      "metadata": {
        "id": "4vYB52H770qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wpKDwn9n71NH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}